
Device of accleration:  cuda
2024-01-27 16:33:24,403 - Saving current state to /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt
2024-01-27 16:33:28,207 - Model weights saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/pytorch_model.bin
2024-01-27 16:33:28,210 - Optimizer state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/optimizer.bin
2024-01-27 16:33:28,211 - Scheduler state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/scheduler.bin
2024-01-27 16:33:28,211 - Sampler state for dataloader 0 saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/sampler.bin
2024-01-27 16:33:28,211 - Sampler state for dataloader 1 saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/sampler_1.bin
2024-01-27 16:33:28,212 - Gradient scaler state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/scaler.pt
2024-01-27 16:33:28,220 - Random states saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/random_states_0.pkl
2024-01-27 16:33:28,220 - Saving the state of AcceleratedScheduler to /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_162936/chkpt/custom_checkpoint_0.pkl
2024-01-27 16:33:28,222 - Started checkpointing

  0%|          | 1/669300 [01:16<14230:24:55, 76.54s/it]Traceback (most recent call last):
  File "/nlsasfs/home/nltm-st/sujitk/yash-mtp/src/wav2vec2/main_v1_1.py", line 339, in <module>
    outputs = model(**batch)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/accelerate/utils/operations.py", line 659, in forward
    return model_forward(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/accelerate/utils/operations.py", line 647, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/yash-mtp/src/common/Model.py", line 157, in forward
    outputs = self.wav2vec2(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1579, in forward
    encoder_outputs = self.encoder(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 908, in forward
    layer_outputs = layer(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 742, in forward
    hidden_states = hidden_states + self.feed_forward(self.final_layer_norm(hidden_states))
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 39.59 GiB total capacity; 37.48 GiB already allocated; 53.19 MiB free; 38.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF