
Device of accleration:  cuda
2024-01-27 16:38:27,750 - Saving current state to /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt
2024-01-27 16:38:31,574 - Model weights saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/pytorch_model.bin
2024-01-27 16:38:31,576 - Optimizer state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/optimizer.bin
2024-01-27 16:38:31,577 - Scheduler state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/scheduler.bin
2024-01-27 16:38:31,577 - Sampler state for dataloader 0 saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/sampler.bin
2024-01-27 16:38:31,577 - Sampler state for dataloader 1 saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/sampler_1.bin
2024-01-27 16:38:31,578 - Gradient scaler state saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/scaler.pt
2024-01-27 16:38:31,582 - Random states saved in /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2//nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/random_states_0.pkl
2024-01-27 16:38:31,582 - Saving the state of AcceleratedScheduler to /nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/nlsasfs/home/nltm-st/sujitk/yash-mtp/models/wav2vec2/saved-model-20240127_163758/chkpt/custom_checkpoint_0.pkl
2024-01-27 16:38:31,583 - Started checkpointing

  0%|          | 1/669300 [01:11<13272:35:23, 71.39s/it]Traceback (most recent call last):
  File "/nlsasfs/home/nltm-st/sujitk/yash-mtp/src/wav2vec2/main_v1_1.py", line 339, in <module>
    outputs = model(**batch)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/accelerate/utils/operations.py", line 659, in forward
    return model_forward(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/accelerate/utils/operations.py", line 647, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
    return func(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/yash-mtp/src/common/Model.py", line 157, in forward
    outputs = self.wav2vec2(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1579, in forward
    encoder_outputs = self.encoder(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 908, in forward
    layer_outputs = layer(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 737, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 609, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1)
  File "/nlsasfs/home/nltm-st/sujitk/miniconda3/envs/wave2vec/lib/python3.9/site-packages/torch/nn/functional.py", line 1843, in softmax
    ret = input.softmax(dim)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 39.59 GiB total capacity; 37.57 GiB already allocated; 11.19 MiB free; 38.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF