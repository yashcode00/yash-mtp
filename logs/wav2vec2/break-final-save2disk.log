Loading the data from the disk.. wait
Current directory /nlsasfs/home/nltm-st/sujitk/yash-mtp/datasets/combined-resampled_data_SilenceAndTwoSecond
['hin', 'mar', 'ben', 'mal', 'asm', 'guj', 'tel', 'odi', 'kan', 'pun', 'tam', 'eng']
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [1:24:21<15:27:52, 5061.11s/it] 17%|█▋        | 2/12 [1:46:45<7:59:09, 2874.93s/it]  25%|██▌       | 3/12 [3:08:25<9:29:55, 3799.48s/it] 33%|███▎      | 4/12 [3:31:36<6:19:49, 2848.65s/it] 42%|████▏     | 5/12 [4:46:23<6:41:17, 3439.57s/it] 50%|█████     | 6/12 [5:58:35<6:14:18, 3743.00s/it] 58%|█████▊    | 7/12 [6:20:54<4:06:25, 2957.14s/it] 67%|██████▋   | 8/12 [7:18:08<3:27:15, 3108.90s/it] 75%|███████▌  | 9/12 [7:58:36<2:24:48, 2896.08s/it] 83%|████████▎ | 10/12 [9:12:14<1:52:11, 3365.82s/it] 92%|█████████▏| 11/12 [10:29:34<1:02:35, 3755.75s/it]100%|██████████| 12/12 [10:49:03<00:00, 2968.80s/it]  100%|██████████| 12/12 [10:49:03<00:00, 3245.32s/it]
Processing hin
Total 159805 samples loaded of hin language.
Processing mar
Total 43755 samples loaded of mar language.
Processing ben
Total 158331 samples loaded of ben language.
Processing mal
Total 44853 samples loaded of mal language.
Processing asm
Total 144794 samples loaded of asm language.
Processing guj
Total 140033 samples loaded of guj language.
Processing tel
Total 45042 samples loaded of tel language.
Processing odi
Total 110305 samples loaded of odi language.
Processing kan
Total 79265 samples loaded of kan language.
Processing pun
Total 142335 samples loaded of pun language.
Processing tam
Total 150498 samples loaded of tam language.
Processing eng
Total 39198 samples loaded of eng language.
Total length of the Dataset:  1258214
                       name  ... language
0  hi_SHA1P_C_r005_s023_160  ...      hin
1  hi_SHA1P_M_r011_s013_132  ...      hin
2  hi_SHA1P_M_r010_s092_146  ...      hin
3                 hin1617_5  ...      hin
4  hi_SHA1P_M_r009_s027_108  ...      hin

[5 rows x 4 columns]
name                                      hi_SHA1P_C_r005_s023_160
path             /nlsasfs/home/nltm-st/sujitk/yash-mtp/datasets...
sampling_rate                                                16000
language                                                       hin
Name: 0, dtype: object
Labels:  ['hin' 'mar' 'ben' 'mal' 'asm' 'guj' 'tel' 'odi' 'kan' 'pun' 'tam' 'eng']

Train df is  (1006571, 4)
Validation df is  (251643, 4)
Downloading and preparing dataset csv/default to /nlsasfs/home/nltm-st/sujitk/.cache/huggingface/datasets/csv/default-429389713de46528/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...
Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 11475.52it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 21.14it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 10000 examples [00:01, 5722.11 examples/s]Generating train split: 70000 examples [00:01, 50085.65 examples/s]Generating train split: 130000 examples [00:01, 101712.21 examples/s]Generating train split: 190000 examples [00:02, 158944.23 examples/s]Generating train split: 250000 examples [00:02, 217516.79 examples/s]Generating train split: 310000 examples [00:02, 276351.21 examples/s]Generating train split: 370000 examples [00:02, 328999.55 examples/s]Generating train split: 430000 examples [00:02, 375730.26 examples/s]Generating train split: 490000 examples [00:02, 412990.26 examples/s]Generating train split: 550000 examples [00:02, 444316.69 examples/s]Generating train split: 610000 examples [00:02, 468873.55 examples/s]Generating train split: 670000 examples [00:02, 483772.46 examples/s]Generating train split: 730000 examples [00:03, 497814.56 examples/s]Generating train split: 790000 examples [00:03, 505736.97 examples/s]Generating train split: 850000 examples [00:03, 512373.56 examples/s]Generating train split: 910000 examples [00:03, 516199.76 examples/s]Generating train split: 970000 examples [00:03, 521945.57 examples/s]                                                                     Generating validation split: 0 examples [00:00, ? examples/s]Generating validation split: 60000 examples [00:00, 525865.60 examples/s]Generating validation split: 120000 examples [00:00, 531970.94 examples/s]Generating validation split: 180000 examples [00:00, 528996.48 examples/s]Generating validation split: 240000 examples [00:00, 530331.15 examples/s]                                                                          Dataset csv downloaded and prepared to /nlsasfs/home/nltm-st/sujitk/.cache/huggingface/datasets/csv/default-429389713de46528/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.30it/s]100%|██████████| 2/2 [00:00<00:00, 18.17it/s]
Dataset({
    features: ['name', 'path', 'sampling_rate', 'language'],
    num_rows: 1006571
})
Dataset({
    features: ['name', 'path', 'sampling_rate', 'language'],
    num_rows: 251643
})
Saving the dataset to be further use at  /nlsasfs/home/nltm-st/sujitk/yash-mtp/datasets/wav2vec2/combined-saved-dataset.hf
Saving the dataset (0/1 shards):   0%|          | 0/1006571 [00:00<?, ? examples/s]Saving the dataset (0/1 shards):  28%|██▊       | 280000/1006571 [00:00<00:00, 2703106.40 examples/s]Saving the dataset (0/1 shards):  61%|██████    | 612000/1006571 [00:00<00:00, 3052852.34 examples/s]Saving the dataset (0/1 shards):  93%|█████████▎| 933000/1006571 [00:00<00:00, 3120295.12 examples/s]Saving the dataset (1/1 shards): 100%|██████████| 1006571/1006571 [00:00<00:00, 3120295.12 examples/s]                                                                                                      Saving the dataset (0/1 shards):   0%|          | 0/251643 [00:00<?, ? examples/s]Saving the dataset (1/1 shards): 100%|██████████| 251643/251643 [00:00<00:00, 3118799.49 examples/s]                                                                                                    Work done mate
